{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3kV4ktGWGN3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Initialization\n",
        "ACTION_SPACE = ('P', 'Q')\n",
        "States=[i for i in range(1,13)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZIGmWCbWGN5"
      },
      "outputs": [],
      "source": [
        "States"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blwDeMz7WGN6"
      },
      "outputs": [],
      "source": [
        "actions = {1: ('P','Q'),\n",
        "           2: ('P', 'Q'),\n",
        "           3: ('P', 'Q'),\n",
        "           4: ('P', 'Q'),\n",
        "           5: ('P', 'Q'),\n",
        "           6: ('P', 'Q'),\n",
        "           7: ('P', 'Q'),\n",
        "           8: ('P', 'Q'),\n",
        "           9: ('P', 'Q'),\n",
        "          10: ('P', 'Q')\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQsIM-n_WGN6"
      },
      "outputs": [],
      "source": [
        "probs = {\n",
        "    (1,'P',2): 0.99,\n",
        "    (1,'P',11): 0.01,\n",
        "    (1,'Q',11): 1,\n",
        "    (2,'P',3): 0.90,\n",
        "    (2,'P',11): 0.10,\n",
        "    (2,'Q',11):1,\n",
        "    (3,'P',4): 0.80,\n",
        "    (3,'P',11): 0.20,\n",
        "    (3,'Q',11):1,\n",
        "    (4,'P',5): 0.70,\n",
        "    (4,'P',11): 0.30,\n",
        "    (4,'Q',11):1,\n",
        "    (5,'P',6): 0.60,\n",
        "    (5,'P',11): 0.40,\n",
        "    (5,'Q',11):1,\n",
        "    (6,'P',7): 0.50,\n",
        "    (6,'P',11): 0.50,\n",
        "    (6,'Q',11):1,\n",
        "    (7,'P',8): 0.40,\n",
        "    (7,'P',11): 0.60,\n",
        "    (7,'Q',11):1,\n",
        "    (8,'P',9): 0.30,\n",
        "    (8,'P',11): 0.70,\n",
        "    (8,'Q',11):1,\n",
        "    (9,'P',10): 0.20,\n",
        "    (9,'P',11): 0.80,\n",
        "    (9,'Q',11):1,\n",
        "    (10,'P',12): 0.1,\n",
        "    (10,'P',11): 0.9,\n",
        "    (10,'Q',11):1,\n",
        "  }\n",
        "REWARDS={\n",
        "    (1,'P',2): 10,\n",
        "    (1,'P',11): 0,\n",
        "    (1,'Q',11): 0,\n",
        "    (2,'P',3): 50,\n",
        "    (2,'P',11): -10,\n",
        "    (2,'Q',11):0,\n",
        "    (3,'P',4): 100,\n",
        "    (3,'P',11): -60,\n",
        "    (3,'Q',11):0,\n",
        "    (4,'P',5): 500,\n",
        "    (4,'P',11): -160,\n",
        "    (4,'Q',11):0,\n",
        "    (5,'P',6): 1000,\n",
        "    (5,'P',11): -660,\n",
        "    (5,'Q',11):0,\n",
        "    (6,'P',7): 5000,\n",
        "    (6,'P',11): -1660,\n",
        "    (6,'Q',11):0,\n",
        "    (7,'P',8): 10000,\n",
        "    (7,'P',11): -6660,\n",
        "    (7,'Q',11):0,\n",
        "    (8,'P',9): 50000,\n",
        "    (8,'P',11): -16660,\n",
        "    (8,'Q',11):0,\n",
        "    (9,'P',10): 100000,\n",
        "    (9,'P',11): -66660,\n",
        "    (9,'Q',11):0,\n",
        "    (10,'P',12):500000,\n",
        "    (10,'P',11):-166660,\n",
        "    (10,'Q',11):0,\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm94x642WGN7"
      },
      "outputs": [],
      "source": [
        "def is_terminal(s):\n",
        "    return s in [11,12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITqX-uhJWGN8"
      },
      "outputs": [],
      "source": [
        "transition_probs = {}\n",
        "# the key is (s, a, s'), the value is the probability\n",
        "# that is, transition_probs[(s, a, s')] = p(s' | s, a)\n",
        "# any key NOT present will considered to be impossible (i.e. probability 0)\n",
        "rewards={}\n",
        "for s in States:\n",
        "    if not is_terminal(s):\n",
        "        for a in ACTION_SPACE:\n",
        "            for s2 in States:\n",
        "                if (s,a,s2) in probs:\n",
        "                    transition_probs[(s, a, s2)]=probs.get((s, a, s2),0)\n",
        "                else:\n",
        "                    transition_probs[(s, a, s2)]=0\n",
        "                if (s,a,s2) in REWARDS:\n",
        "                    rewards[(s, a, s2)]=REWARDS.get((s, a, s2),0)\n",
        "                else:\n",
        "                    rewards[(s, a, s2)]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHBcXXpNWGN9"
      },
      "outputs": [],
      "source": [
        "transition_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ye4ymcoWGN9"
      },
      "outputs": [],
      "source": [
        "rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFt9gf6QWGN-"
      },
      "outputs": [],
      "source": [
        "### fixed policy always play ###\n",
        "policy = {\n",
        "    1:'P',\n",
        "    2:'P',\n",
        "    3:'P',\n",
        "    4:'P',\n",
        "    5:'P',\n",
        "    6:'P',\n",
        "    7:'P',\n",
        "    8:'P',    \n",
        "    9:'P',\n",
        "    10:'P', \n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRUJ50xrWGN-"
      },
      "outputs": [],
      "source": [
        "def policy_evaluation(policy):\n",
        "    # initialize V(s) = 0\n",
        "    V = {}\n",
        "    for s in States:\n",
        "        V[s] = 0\n",
        "    SMALL_ENOUGH = 1e-3 # threshold for convergence\n",
        "    gamma = 1 # discount factor\n",
        "    # repeat until convergence\n",
        "    it = 0\n",
        "    while True:\n",
        "        biggest_change = 0\n",
        "        for s in States:\n",
        "            if is_terminal(s):\n",
        "                V[s]=0\n",
        "            else:\n",
        "                old_v=V[s]\n",
        "                new_v = 0 # we will accumulate the answer\n",
        "                a=policy.get(s)\n",
        "                for s2 in States:\n",
        "                    # reward is a function of (s, a, s')\n",
        "                    r = rewards.get((s, a, s2),0)\n",
        "                    new_v += transition_probs.get((s, a, s2),0) * (r + gamma * V[s2])\n",
        "                # after done getting the new value, update the value table\n",
        "                V[s] = new_v\n",
        "                biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
        "        print(\"iter:\", it, \"biggest_change:\", biggest_change)\n",
        "        it += 1\n",
        "        if biggest_change < SMALL_ENOUGH:\n",
        "            break\n",
        "    print(\"\\n\\n\")\n",
        "    return(V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZxdsAt8WGN_"
      },
      "outputs": [],
      "source": [
        "Values=policy_evaluation(policy)\n",
        "Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWoVLykQWGN_"
      },
      "outputs": [],
      "source": [
        "### fixed policy ###\n",
        "policy = {\n",
        "    1:'P',\n",
        "    2:'P',\n",
        "    3:'P',\n",
        "    4:'P',\n",
        "    5:'P',\n",
        "    6:'Q',\n",
        "    7:'Q',\n",
        "    8:'Q',    \n",
        "    9:'Q',\n",
        "    10:'Q', \n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i09snEaQWGN_"
      },
      "outputs": [],
      "source": [
        "Values=policy_evaluation(policy)\n",
        "Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw6ouC2RWGN_"
      },
      "outputs": [],
      "source": [
        "for s in actions.keys():\n",
        "    policy[s] = np.random.choice(actions.get(s))\n",
        "policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmm-ymN3WGN_"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    gamma = 1\n",
        "    # policy evaluation step - we already know how to do this!\n",
        "    print(policy)\n",
        "    V = policy_evaluation(policy)\n",
        "    # policy improvement step\n",
        "    is_policy_converged = True\n",
        "    for s in States:\n",
        "        if not is_terminal(s):\n",
        "            old_a = policy[s]\n",
        "            new_a = None\n",
        "            best_value = float('-inf')\n",
        "            # loop through all possible actions to find the best current action\n",
        "            for a in actions.get(s):\n",
        "                v = 0\n",
        "                for s2 in States:\n",
        "                # reward is a function of (s, a, s'), 0 if not specified\n",
        "                    r = rewards.get((s, a, s2), 0)\n",
        "                    v += transition_probs.get((s, a, s2), 0) * (r + gamma * V[s2])\n",
        "                if v > best_value:\n",
        "                    best_value = v\n",
        "                    new_a = a\n",
        "                  # new_a now represents the best action in this state\n",
        "                    policy[s] = new_a\n",
        "            if new_a != old_a:\n",
        "                is_policy_converged = False\n",
        "    if is_policy_converged:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkUBPn7PWGOA"
      },
      "outputs": [],
      "source": [
        "V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_QZIpajWGOA"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}