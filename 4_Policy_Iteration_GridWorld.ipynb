{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGSUsLJJWOVv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Initialization\n",
        "ACTION_SPACE = ('U', 'D', 'L', 'R')\n",
        "States=[(0, 0),\n",
        " (0, 1),\n",
        " (0, 2),\n",
        " (0, 3),\n",
        " (1, 0),\n",
        " (1, 2),\n",
        " (1, 3),\n",
        " (2, 0),\n",
        " (2, 1),\n",
        " (2, 2),\n",
        " (2, 3)]\n",
        "REWARDS = {(0, 3): 1, (1, 3): -1}\n",
        "actions = {\n",
        "    (0, 0): ('D', 'R'),\n",
        "    (0, 1): ('L', 'R'),\n",
        "    (0, 2): ('L', 'D', 'R'),\n",
        "    (1, 0): ('U', 'D'),\n",
        "    (1, 2): ('U', 'D', 'R'),\n",
        "    (2, 0): ('U', 'R'),\n",
        "    (2, 1): ('L', 'R'),\n",
        "    (2, 2): ('L', 'R', 'U'),\n",
        "    (2, 3): ('L', 'U'),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rioee3BEWOVx"
      },
      "outputs": [],
      "source": [
        "def is_terminal(s):\n",
        "    return s in [(0, 3),(1, 3)] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEYJ-iScWOVy"
      },
      "outputs": [],
      "source": [
        "is_terminal((2,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p-t_J0gWOVy"
      },
      "outputs": [],
      "source": [
        "def get_next_state(s, a):\n",
        "    # this answers: where would I end up if I perform action 'a' in state 's'?\n",
        "    i, j = s[0], s[1]\n",
        "    # if this action moves you somewhere else, then it will be in this dictionary\n",
        "    if a in actions[(i, j)]:\n",
        "        if a == 'U':\n",
        "            i -= 1\n",
        "        elif a == 'D':\n",
        "            i += 1\n",
        "        elif a == 'R':\n",
        "            j += 1\n",
        "        elif a == 'L':\n",
        "            j -= 1\n",
        "    return i, j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRKeUpU1WOVy"
      },
      "outputs": [],
      "source": [
        "### define transition probabilities\n",
        "  # the key is (s, a, s'), the value is the probability\n",
        "  # that is, transition_probs[(s, a, s')] = p(s' | s, a)\n",
        "  # any key NOT present will considered to be impossible (i.e. probability 0)\n",
        "transition_probs = {}\n",
        "  # to reduce the dimensionality of the dictionary, we'll use deterministic\n",
        "  # rewards, r(s, a, s')\n",
        "  # note: you could make it simpler by using r(s') since the reward doesn't\n",
        "  # actually depend on (s, a)\n",
        "rewards = {}\n",
        "\n",
        "\n",
        "for s in States:\n",
        "    if not is_terminal(s):\n",
        "        for a in ACTION_SPACE:\n",
        "            s2 = get_next_state(s, a)\n",
        "            transition_probs[(s, a, s2)] = 1\n",
        "            if s2 in REWARDS:\n",
        "                rewards[(s, a, s2)] = REWARDS[s2]\n",
        "            else:\n",
        "                rewards[(s, a, s2)] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXzE2ERBWOVz"
      },
      "outputs": [],
      "source": [
        "transition_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5EtVSSpWOVz"
      },
      "outputs": [],
      "source": [
        "rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DWLtmdcWOVz"
      },
      "outputs": [],
      "source": [
        "### fixed policy ###\n",
        "policy = {\n",
        "    (2, 0): 'U',\n",
        "    (1, 0): 'U',\n",
        "    (0, 0): 'R',\n",
        "    (0, 1): 'R',\n",
        "    (0, 2): 'R',\n",
        "    (1, 2): 'U',\n",
        "    (2, 1): 'R',\n",
        "    (2, 2): 'U',\n",
        "    (2, 3): 'L',\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB0WYnjnWOV0"
      },
      "outputs": [],
      "source": [
        "policy.get((2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxQM8gpnWOV0"
      },
      "outputs": [],
      "source": [
        "transition_probs.get(((0, 0), 'U', (0, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEvQDyvXWOV0"
      },
      "outputs": [],
      "source": [
        "def policy_evaluation(policy):\n",
        "    # initialize V(s) = 0\n",
        "    V = {}\n",
        "    for s in States:\n",
        "        V[s] = 0\n",
        "    SMALL_ENOUGH = 1e-3 # threshold for convergence\n",
        "    gamma = 0.9 # discount factor\n",
        "    # repeat until convergence\n",
        "    it = 0\n",
        "    while True:\n",
        "        biggest_change = 0\n",
        "        for s in States:\n",
        "            \n",
        "            if is_terminal(s):\n",
        "                V[s]=0\n",
        "            else:\n",
        "                old_v=V[s]\n",
        "                new_v = 0 # we will accumulate the answer\n",
        "                a=policy.get(s)\n",
        "                for s2 in States:\n",
        "                    r = rewards.get((s, a, s2),0)\n",
        "                    new_v += transition_probs.get((s, a, s2),0) * (r + gamma * V[s2])\n",
        "                # after done getting the new value, update the value table\n",
        "                V[s] = new_v\n",
        "                biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
        "        print(\"iter:\", it, \"biggest_change:\", biggest_change)\n",
        "        it += 1\n",
        "        if biggest_change < SMALL_ENOUGH:\n",
        "            break\n",
        "    print(\"\\n\\n\")\n",
        "    return(V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju033di5WOV0"
      },
      "outputs": [],
      "source": [
        "Values=policy_evaluation(policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxS6ZgYpWOV1"
      },
      "outputs": [],
      "source": [
        "def print_values(V, rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(columns):\n",
        "            v = V.get((i,j), 0)\n",
        "            if v >= 0:\n",
        "                print(\" %.2f|\" % v, end=\"\")\n",
        "            else:\n",
        "                print(\"%.2f|\" % v, end=\"\") # -ve sign takes up an extra space\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2wUNsuOWOV1"
      },
      "outputs": [],
      "source": [
        "print_values(Values, 3,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyxIKQLAWOV2"
      },
      "outputs": [],
      "source": [
        "Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jA6LKRDWOV2"
      },
      "outputs": [],
      "source": [
        "for s in actions.keys():\n",
        "    policy[s] = np.random.choice(actions.get(s))\n",
        "policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3XmE0j1WOV3"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    gamma = 0.9\n",
        "    # policy evaluation step - we already know how to do this!\n",
        "    print(policy)\n",
        "    V = policy_evaluation(policy)\n",
        "    # policy improvement step\n",
        "    is_policy_converged = True\n",
        "    for s in States:\n",
        "        if not is_terminal(s):\n",
        "            old_a = policy[s]\n",
        "            new_a = None\n",
        "            best_value = float('-inf')\n",
        "            # loop through all possible actions to find the best current action\n",
        "            for a in actions.get(s):\n",
        "                v = 0\n",
        "                for s2 in States:\n",
        "                # reward is a function of (s, a, s'), 0 if not specified\n",
        "                    r = rewards.get((s, a, s2), 0)\n",
        "                    v += transition_probs.get((s, a, s2), 0) * (r + gamma * V[s2])\n",
        "                if v > best_value:\n",
        "                    best_value = v\n",
        "                    new_a = a\n",
        "                  # new_a now represents the best action in this state\n",
        "                    policy[s] = new_a\n",
        "            if new_a != old_a:\n",
        "                is_policy_converged = False\n",
        "    if is_policy_converged:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtCdNa_EWOV3"
      },
      "outputs": [],
      "source": [
        "def print_policy(policy,rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(columns):\n",
        "              a = policy.get((i,j), ' ')\n",
        "              print(\"  %s  |\" % a, end=\"\")\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sxqn-vmWOV4"
      },
      "outputs": [],
      "source": [
        "print_policy(policy,rows=3,columns=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcyk0gbmWOV4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}