{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqKh_mmBWile"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import GridWorld\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raK1Ic6UWilg"
      },
      "outputs": [],
      "source": [
        "robot=GridWorld.grid_world()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBu7_nQFWili"
      },
      "outputs": [],
      "source": [
        "def print_values(V, rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(columns):\n",
        "            v = V.get((i,j), 0)\n",
        "            if v >= 0:\n",
        "                print(\" %.2f|\" % v, end=\"\")\n",
        "            else:\n",
        "                print(\"%.2f|\" % v, end=\"\") # -ve sign takes up an extra space\n",
        "        print(\"\")\n",
        "def print_policy(policy,rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(columns):\n",
        "            a = policy.get((i,j), ' ')\n",
        "            print(\"  %s  |\" % a, end=\"\")\n",
        "        print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbEcTgwiWilj"
      },
      "outputs": [],
      "source": [
        "def max_dict(d):\n",
        "    # returns the argmax (key) and max (value) from a dictionary\n",
        "    # put this into a function since we are using it so often\n",
        "\n",
        "    # find max val\n",
        "    max_val = max(d.values())\n",
        "\n",
        "    # find keys corresponding to max val\n",
        "    max_keys = [key for key, val in d.items() if val == max_val]\n",
        "\n",
        "    return np.random.choice(max_keys), max_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw9mUaMeWilk"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy(Q, s, eps=0.1):\n",
        "    if np.random.random() < eps:\n",
        "        return np.random.choice(robot.ACTION_SPACE)\n",
        "    else:\n",
        "        a_opt = max_dict(Q[s])[0]\n",
        "    return a_opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdH9I6VbWill"
      },
      "outputs": [],
      "source": [
        "# initialize Q(s,a) and returns\n",
        "Q = {}\n",
        "sample_counts = {}\n",
        "for s in robot.States:\n",
        "    Q[s] = {}\n",
        "    sample_counts[s] = {}\n",
        "    for a in robot.ACTION_SPACE:\n",
        "        Q[s][a] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhTuOJpoWill"
      },
      "outputs": [],
      "source": [
        "Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-osyKmrWilm"
      },
      "outputs": [],
      "source": [
        "GAMMA=0.9\n",
        "ALPHA = 0.1\n",
        "# let's also keep track of how many times Q[s] has been updated\n",
        "update_counts = {}\n",
        "reward_per_episode = []\n",
        "for it in range(10000):\n",
        "    if it % 1000 == 0:\n",
        "        print(\"it:\", it)\n",
        "    # begin a new episode\n",
        "    s=robot.initial_state()\n",
        "#    print(s)\n",
        "    a = epsilon_greedy(Q, s, eps=0.1)\n",
        "#    print(a)\n",
        "    done=False\n",
        "    episode_reward = 0\n",
        "    while not done:\n",
        "        # perform action and get next state + reward\n",
        "        s2, r, done=robot.step(a)\n",
        "      #  print(r)\n",
        "        # update reward\n",
        "        episode_reward += r\n",
        "        # get next action\n",
        "        a2 = epsilon_greedy(Q, s2, eps=0.1)\n",
        "     #   print(a2)\n",
        "        # update Q(s,a)\n",
        "        Q[s][a] = Q[s][a] + ALPHA*(r + GAMMA*Q[s2][a2] - Q[s][a])\n",
        "\n",
        "        # we would like to know how often Q(s) has been updated too\n",
        "        update_counts[s] = update_counts.get(s,0) + 1\n",
        "\n",
        "        # next state becomes current state\n",
        "        s = s2\n",
        "        a = a2\n",
        "\n",
        "        # log the reward for this episode\n",
        "        reward_per_episode.append(episode_reward)\n",
        "\n",
        "plt.plot(reward_per_episode)\n",
        "plt.title(\"reward_per_episode\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ9Re0sMWiln"
      },
      "outputs": [],
      "source": [
        "policy = {}\n",
        "V = {}\n",
        "for s in robot.actions.keys():\n",
        "    a, max_q = max_dict(Q[s])\n",
        "    policy[s] = a\n",
        "    V[s] = max_q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFY63w6QWiln"
      },
      "outputs": [],
      "source": [
        "print_policy(policy,3,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woQqyF77Wilo"
      },
      "outputs": [],
      "source": [
        "print_values(V,3,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO20Lbh2Wilo"
      },
      "outputs": [],
      "source": [
        "update_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_7KE1xdWilo"
      },
      "outputs": [],
      "source": [
        "state_sample_count_arr = np.zeros((3, 4))\n",
        "for i in range(3):\n",
        "    for j in range(4):\n",
        "        if (i, j) in update_counts:\n",
        "            state_sample_count_arr[i,j] = update_counts[(i, j)]\n",
        "    df = pd.DataFrame(state_sample_count_arr)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrVdrm8GWilp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}